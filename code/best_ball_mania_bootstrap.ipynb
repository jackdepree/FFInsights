{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set working directory\n",
    "import os\n",
    "current_dir = os.getcwd()\n",
    "os.chdir(current_dir.replace('\\code', '\\data'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data_ii = pd.read_csv('best_ball_mania_ii.csv')\n",
    "data_iii = pd.read_csv('best_ball_mania_iii.csv')\n",
    "data_iv = pd.read_csv('best_ball_mania_iv.csv')\n",
    "\n",
    "# Increase 'roster_points' and 'pick_points' for dataset iv by 4.5\n",
    "data_iv['pick_points'] = data_iv['pick_points']*4.5\n",
    "data_iv['roster_points'] = data_iv['roster_points']*4.5\n",
    "\n",
    "# Columns that are in all datasets\n",
    "cols = list(set(data_ii.columns) & set(data_iii.columns) & set(data_iv.columns))\n",
    "\n",
    "# Filter columns\n",
    "data_ii = data_ii[cols]\n",
    "data_iii = data_iii[cols]\n",
    "data_iv = data_iv[cols]\n",
    "\n",
    "# Concatenate data\n",
    "data = pd.concat([data_ii, data_iii, data_iv], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename 'tournament_entry_id' to 'team_id'\n",
    "data = data.rename(columns={'tournament_entry_id': 'team_id'})\n",
    "\n",
    "data = data.drop(columns=['clock', 'tournament_round_number', 'bye_week', 'draft_time'])\n",
    "\n",
    "# Fit a polynomial regression\n",
    "p = np.poly1d(np.polyfit(data['overall_pick_number'], data['pick_points'], 2))\n",
    "data['poly_points'] = p(data['overall_pick_number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstrap the points per position rank\n",
    "# Find distributions of points per position rank for each position\n",
    "# Simulate a single draft with 30 QBs, 70 RBs, 100 WRs, and 30 TEs\n",
    "# Each pick is a random number from the distribution of *centered* points per position rank\n",
    "# Find the chance that RB1 scores more points than WR1 and so on\n",
    "\n",
    "def polynomial_points(position_name):\n",
    "    data_grouped = data.groupby(['draft_id', 'position_name', 'overall_pick_number'])[\"pick_points\"].mean().reset_index()\n",
    "    data_grouped = data_grouped[['draft_id', 'position_name', 'overall_pick_number', 'pick_points']]\n",
    "    data_grouped = data_grouped.drop(data_grouped[data_grouped['position_name'] == 'FB'].index)\n",
    "    data_grouped['pos_rank'] = data_grouped.groupby(['draft_id', 'position_name'])['overall_pick_number'].rank()\n",
    "    \n",
    "    data_grouped = data_grouped[((data_grouped['position_name'] == 'QB') & (data_grouped['pos_rank'] <= 30)) |\n",
    "                                ((data_grouped['position_name'] == 'RB') & (data_grouped['pos_rank'] <= 70)) |\n",
    "                                ((data_grouped['position_name'] == 'WR') & (data_grouped['pos_rank'] <= 100)) |\n",
    "                                ((data_grouped['position_name'] == 'TE') & (data_grouped['pos_rank'] <= 30))]\n",
    "    \n",
    "    p = np.poly1d(np.polyfit(data_grouped[data_grouped['position_name'] == position_name]['pos_rank'],\n",
    "                              data_grouped[data_grouped['position_name'] == position_name]['pick_points'], 3))\n",
    "    \n",
    "    return p\n",
    "\n",
    "def variance_regression(position_name, degree=3):\n",
    "    data_grouped = data.groupby(['draft_id', 'position_name', 'overall_pick_number'])[\"pick_points\"].mean().reset_index()\n",
    "    data_grouped = data_grouped[['draft_id', 'position_name', 'overall_pick_number', 'pick_points']]\n",
    "    data_grouped = data_grouped.drop(data_grouped[data_grouped['position_name'] == 'FB'].index)\n",
    "    data_grouped['pos_rank'] = data_grouped.groupby(['draft_id', 'position_name'])['overall_pick_number'].rank()\n",
    "    \n",
    "    data_grouped = data_grouped[((data_grouped['position_name'] == 'QB') & (data_grouped['pos_rank'] <= 30)) |\n",
    "                                ((data_grouped['position_name'] == 'RB') & (data_grouped['pos_rank'] <= 70)) |\n",
    "                                ((data_grouped['position_name'] == 'WR') & (data_grouped['pos_rank'] <= 100)) |\n",
    "                                ((data_grouped['position_name'] == 'TE') & (data_grouped['pos_rank'] <= 30))]\n",
    "    \n",
    "    grouped_data = data_grouped[data_grouped['position_name'] == position_name].groupby('pos_rank')['pick_points'].std().reset_index()\n",
    "    \n",
    "    # Fit a polynomial regression to the variance data\n",
    "    z = np.polyfit(grouped_data['pos_rank'], grouped_data['pick_points'], degree)\n",
    "    p = np.poly1d(z)\n",
    "    \n",
    "    return p\n",
    "\n",
    "def estimations(position_name, max_rank, starter_rank):\n",
    "    points = polynomial_points(position_name)\n",
    "    variance_series = variance_regression(position_name)\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    df['rank'] = np.arange(1, max_rank+1)\n",
    "    df['pos_rank'] = position_name + df['rank'].astype(str)\n",
    "    df['points'] = points(df['rank'])\n",
    "    \n",
    "    # For variance, fill missing ranks with zero variance\n",
    "    df['variance'] = df['rank'].map(variance_series).fillna(0)\n",
    "    df['top_five'] = df['points'] + 2 * df['variance']\n",
    "    df['bottom_five'] = df['points'] - 2 * df['variance']\n",
    "    \n",
    "    mu = df.loc[df['rank'] == starter_rank, 'points'].values[0]\n",
    "    df['points'] -= mu\n",
    "    df['top_five'] -= mu\n",
    "    df['bottom_five'] -= mu\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Estimations for each position\n",
    "qb = estimations('QB', max_rank=30, starter_rank=12)\n",
    "rb = estimations('RB', max_rank=70, starter_rank=29) # 5 Flex\n",
    "wr = estimations('WR', max_rank=100, starter_rank=41) # 5 Flex\n",
    "te = estimations('TE', max_rank=30, starter_rank=14) # 2 Flex\n",
    "\n",
    "# New df with all positions\n",
    "df_points = pd.concat([qb[['pos_rank', 'points', 'top_five', 'bottom_five']], \n",
    "                       rb[['pos_rank', 'points', 'top_five', 'bottom_five']], \n",
    "                       wr[['pos_rank', 'points', 'top_five', 'bottom_five']], \n",
    "                       te[['pos_rank', 'points', 'top_five', 'bottom_five']]], axis=0)\n",
    "df_points = df_points.sort_values(by='points', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   pos_rank      points    top_five  bottom_five\n",
      "0       WR1  105.142159  234.340977   -24.056660\n",
      "1       QB1  101.793881  231.197223   -27.609460\n",
      "2       WR2  100.839707  230.024119   -28.344706\n",
      "3       WR3   96.643433  225.776479   -32.489613\n",
      "4       RB1   92.590109  220.993035   -35.812818\n",
      "5       WR4   92.551732  221.597256   -36.493793\n",
      "6       QB2   89.759796  231.765024   -52.245433\n",
      "7       TE1   89.401265  168.167722    10.634809\n",
      "8       WR5   88.562997  217.485651   -40.359656\n",
      "9       RB2   86.966839  214.232823   -40.299145\n",
      "10      WR6   84.675624  213.440862   -44.089613\n",
      "11      RB3   81.566312  207.795183   -44.662559\n",
      "12      WR7   80.888007  209.462090   -47.686076\n",
      "13      QB3   78.351185  230.925872   -74.223502\n",
      "14      WR8   77.198540  205.548535   -51.151455\n",
      "15      RB4   76.382626  201.670110   -48.904858\n",
      "16      TE2   74.620818  151.676655    -2.435019\n",
      "17      WR9   73.605618  201.699397   -54.488161\n",
      "18      RB5   71.409878  195.847596   -53.027840\n",
      "19     WR10   70.107635  197.913875   -57.698605\n",
      "20      QB4   67.544897  228.775133   -93.685340\n",
      "21     WR11   66.702985  194.191168   -60.785198\n",
      "22      RB6   66.642167  190.317634   -57.033301\n",
      "23     WR12   63.390064  190.530478   -63.750351\n",
      "24      RB7   62.073590  185.070218   -60.923039\n",
      "25      TE3   61.522896  136.984738   -13.938946\n",
      "26     WR13   60.167264  186.931003   -66.596474\n",
      "27      RB8   57.698245  180.095342   -64.698851\n"
     ]
    }
   ],
   "source": [
    "print(df_points.head(28).reset_index(drop=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
