{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:9: SyntaxWarning: invalid escape sequence '\\c'\n",
      "<>:9: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:9: SyntaxWarning: invalid escape sequence '\\c'\n",
      "<>:9: SyntaxWarning: invalid escape sequence '\\d'\n",
      "C:\\Users\\Jack\\AppData\\Local\\Temp\\ipykernel_15072\\2141329615.py:9: SyntaxWarning: invalid escape sequence '\\c'\n",
      "  os.chdir(current_dir.replace('\\code', '\\data'))\n",
      "C:\\Users\\Jack\\AppData\\Local\\Temp\\ipykernel_15072\\2141329615.py:9: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  os.chdir(current_dir.replace('\\code', '\\data'))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set working directory\n",
    "import os\n",
    "current_dir = os.getcwd()\n",
    "os.chdir(current_dir.replace('\\code', '\\data'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quaterback data\n",
    "import requests\n",
    "from lxml import html\n",
    "import pandas as pd\n",
    "\n",
    "def fetch_data(url_list):\n",
    "    for url in url_list:\n",
    "        # Send a GET request to fetch the webpage content\n",
    "        response = requests.get(url)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            # Parse the HTML content\n",
    "            tree = html.fromstring(response.content)\n",
    "\n",
    "            # Scrape the list of columns\n",
    "            columns = tree.xpath('//table[@id=\"passing\"]//thead//th/text()')\n",
    "            columns = [c.strip() for c in columns]\n",
    "\n",
    "            # Remove the first column\n",
    "            columns = columns[1:]\n",
    "            \n",
    "            # Scrape the list of rows\n",
    "            rows = tree.xpath('//table[@id=\"passing\"]//tbody//tr')\n",
    "            data = []\n",
    "\n",
    "            # Extract data from each row\n",
    "            for row in rows:\n",
    "                row_data = []\n",
    "                for r in row.xpath('.//td'):\n",
    "                    row_data.append(r.text_content().strip())\n",
    "                # Ensure each row has the same number of columns as the header\n",
    "                while len(row_data) < len(columns):\n",
    "                    row_data.append(None)\n",
    "                while len(row_data) > len(columns):\n",
    "                    row_data.pop()\n",
    "                data.append(row_data)  # Append the row data to the data list\n",
    "\n",
    "            # Create a DataFrame\n",
    "            df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "            # Save the DataFrame to a CSV file without using any column as an index\n",
    "            df.to_csv(f\"{url_list[url]}_pfr_passing.csv\", index=False)\n",
    "        else:\n",
    "            print(f\"Failed to fetch the webpage. Status code: {response.status_code}\")\n",
    "\n",
    "# URL list\n",
    "qb_list = {\n",
    "    'https://www.pro-football-reference.com/years/2012/passing.htm': 2012, \n",
    "    'https://www.pro-football-reference.com/years/2013/passing.htm': 2013,\n",
    "    'https://www.pro-football-reference.com/years/2014/passing.htm': 2014,\n",
    "    'https://www.pro-football-reference.com/years/2015/passing.htm': 2015,\n",
    "    'https://www.pro-football-reference.com/years/2016/passing.htm': 2016,\n",
    "    'https://www.pro-football-reference.com/years/2017/passing.htm': 2017,\n",
    "    'https://www.pro-football-reference.com/years/2018/passing.htm': 2018,\n",
    "    'https://www.pro-football-reference.com/years/2019/passing.htm': 2019,\n",
    "    'https://www.pro-football-reference.com/years/2020/passing.htm': 2020,\n",
    "    'https://www.pro-football-reference.com/years/2021/passing.htm': 2021,\n",
    "    'https://www.pro-football-reference.com/years/2022/passing.htm': 2022,\n",
    "    'https://www.pro-football-reference.com/years/2023/passing.htm': 2023\n",
    "}\n",
    "\n",
    "fetch_data(qb_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Age</th>\n",
       "      <th>Team</th>\n",
       "      <th>Pos</th>\n",
       "      <th>G</th>\n",
       "      <th>GS</th>\n",
       "      <th>QBrec</th>\n",
       "      <th>Cmp</th>\n",
       "      <th>Att</th>\n",
       "      <th>Cmp%</th>\n",
       "      <th>...</th>\n",
       "      <th>Rate</th>\n",
       "      <th>QBR</th>\n",
       "      <th>Sk</th>\n",
       "      <th>Yds.1</th>\n",
       "      <th>Sk%</th>\n",
       "      <th>NY/A</th>\n",
       "      <th>ANY/A</th>\n",
       "      <th>4QC</th>\n",
       "      <th>GWD</th>\n",
       "      <th>Awards</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Drew Brees</td>\n",
       "      <td>33.0</td>\n",
       "      <td>NOR</td>\n",
       "      <td>QB</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>7-9-0</td>\n",
       "      <td>422.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>...</td>\n",
       "      <td>96.3</td>\n",
       "      <td>68.7</td>\n",
       "      <td>26.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>3.74</td>\n",
       "      <td>7.17</td>\n",
       "      <td>7.17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>PB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Matthew Stafford</td>\n",
       "      <td>24.0</td>\n",
       "      <td>DET</td>\n",
       "      <td>QB</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4-12-0</td>\n",
       "      <td>435.0</td>\n",
       "      <td>727.0</td>\n",
       "      <td>59.8</td>\n",
       "      <td>...</td>\n",
       "      <td>79.8</td>\n",
       "      <td>56.1</td>\n",
       "      <td>29.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>3.84</td>\n",
       "      <td>6.29</td>\n",
       "      <td>5.81</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tony Romo</td>\n",
       "      <td>32.0</td>\n",
       "      <td>DAL</td>\n",
       "      <td>QB</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>8-8-0</td>\n",
       "      <td>425.0</td>\n",
       "      <td>648.0</td>\n",
       "      <td>65.6</td>\n",
       "      <td>...</td>\n",
       "      <td>90.5</td>\n",
       "      <td>65.4</td>\n",
       "      <td>36.0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>5.26</td>\n",
       "      <td>6.78</td>\n",
       "      <td>6.35</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tom Brady</td>\n",
       "      <td>35.0</td>\n",
       "      <td>NWE</td>\n",
       "      <td>QB</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>12-4-0</td>\n",
       "      <td>401.0</td>\n",
       "      <td>637.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>...</td>\n",
       "      <td>98.7</td>\n",
       "      <td>76.1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>4.07</td>\n",
       "      <td>7.00</td>\n",
       "      <td>7.48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>PB,AP OPoY-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Matt Ryan</td>\n",
       "      <td>27.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>QB</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>13-3-0</td>\n",
       "      <td>422.0</td>\n",
       "      <td>615.0</td>\n",
       "      <td>68.6</td>\n",
       "      <td>...</td>\n",
       "      <td>99.1</td>\n",
       "      <td>71.6</td>\n",
       "      <td>28.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>4.35</td>\n",
       "      <td>7.01</td>\n",
       "      <td>7.03</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>PB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Player   Age Team Pos     G    GS   QBrec    Cmp    Att  Cmp%  \\\n",
       "0        Drew Brees  33.0  NOR  QB  16.0  16.0   7-9-0  422.0  670.0  63.0   \n",
       "1  Matthew Stafford  24.0  DET  QB  16.0  16.0  4-12-0  435.0  727.0  59.8   \n",
       "2         Tony Romo  32.0  DAL  QB  16.0  16.0   8-8-0  425.0  648.0  65.6   \n",
       "3         Tom Brady  35.0  NWE  QB  16.0  16.0  12-4-0  401.0  637.0  63.0   \n",
       "4         Matt Ryan  27.0  ATL  QB  16.0  16.0  13-3-0  422.0  615.0  68.6   \n",
       "\n",
       "   ...  Rate   QBR    Sk  Yds.1   Sk%  NY/A  ANY/A  4QC  GWD        Awards  \n",
       "0  ...  96.3  68.7  26.0  190.0  3.74  7.17   7.17  1.0  2.0            PB  \n",
       "1  ...  79.8  56.1  29.0  212.0  3.84  6.29   5.81  3.0  3.0           NaN  \n",
       "2  ...  90.5  65.4  36.0  263.0  5.26  6.78   6.35  5.0  5.0           NaN  \n",
       "3  ...  98.7  76.1  27.0  182.0  4.07  7.00   7.48  1.0  2.0  PB,AP OPoY-3  \n",
       "4  ...  99.1  71.6  28.0  210.0  4.35  7.01   7.03  4.0  6.0            PB  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pass_12 = pd.read_csv('2012_pfr_passing.csv')\n",
    "pass_12.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Receiving and Rushing data\n",
    "import requests\n",
    "from lxml import html\n",
    "import pandas as pd\n",
    "\n",
    "def fetch_data(url_list):\n",
    "    for url in url_list:\n",
    "        # Send a GET request to fetch the webpage content\n",
    "        response = requests.get(url)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            # Parse the HTML content\n",
    "            tree = html.fromstring(response.content)\n",
    "\n",
    "            # Scrape the list of columns\n",
    "            columns = tree.xpath('//table[@id=\"passing\"]//thead//th/text()')\n",
    "            columns = [c.strip() for c in columns]\n",
    "            \n",
    "            # Scrape the list of rows\n",
    "            rows = tree.xpath('//table[@id=\"passing\"]//tbody//tr')\n",
    "            data = []\n",
    "\n",
    "            # Extract data from each row\n",
    "            for row in rows:\n",
    "                row_data = []\n",
    "                for r in row.xpath('.//td'):\n",
    "                    row_data.append(r.text_content().strip())\n",
    "                # Ensure each row has the same number of columns as the header\n",
    "                while len(row_data) < len(columns):\n",
    "                    row_data.append(None)\n",
    "                while len(row_data) > len(columns):\n",
    "                    row_data.pop()\n",
    "                data.append(row_data)  # Append the row data to the data list\n",
    "\n",
    "            # Create a DataFrame\n",
    "            df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "            # Save the DataFrame to a CSV file without using any column as an index\n",
    "            df.to_csv(f\"{url_list[url]}_pfr_passing.csv\", index=False)\n",
    "        else:\n",
    "            print(f\"Failed to fetch the webpage. Status code: {response.status_code}\")\n",
    "\n",
    "# URL list\n",
    "rb_list = {\n",
    "    'https://www.pro-football-reference.com/years/2012/rushing.htm': 2012,\n",
    "    'https://www.pro-football-reference.com/years/2013/rushing.htm': 2013,\n",
    "    'https://www.pro-football-reference.com/years/2014/rushing.htm': 2014,\n",
    "    'https://www.pro-football-reference.com/years/2015/rushing.htm': 2015,\n",
    "    'https://www.pro-football-reference.com/years/2016/rushing.htm': 2016,\n",
    "    'https://www.pro-football-reference.com/years/2017/rushing.htm': 2017,\n",
    "    'https://www.pro-football-reference.com/years/2018/rushing.htm': 2018,\n",
    "    'https://www.pro-football-reference.com/years/2019/rushing.htm': 2019,\n",
    "    'https://www.pro-football-reference.com/years/2020/rushing.htm': 2020,\n",
    "    'https://www.pro-football-reference.com/years/2021/rushing.htm': 2021,\n",
    "    'https://www.pro-football-reference.com/years/2022/rushing.htm': 2022,\n",
    "    'https://www.pro-football-reference.com/years/2023/rushing.htm': 2023\n",
    "}\n",
    "\n",
    "# URL list\n",
    "wr_list = {\n",
    "    'https://www.pro-football-reference.com/years/2012/receiving.htm': 2012,\n",
    "    'https://www.pro-football-reference.com/years/2013/receiving.htm': 2013,\n",
    "    'https://www.pro-football-reference.com/years/2014/receiving.htm': 2014,\n",
    "    'https://www.pro-football-reference.com/years/2015/receiving.htm': 2015,\n",
    "    'https://www.pro-football-reference.com/years/2016/receiving.htm': 2016,\n",
    "    'https://www.pro-football-reference.com/years/2017/receiving.htm': 2017,\n",
    "    'https://www.pro-football-reference.com/years/2018/receiving.htm': 2018,\n",
    "    'https://www.pro-football-reference.com/years/2019/receiving.htm': 2019,\n",
    "    'https://www.pro-football-reference.com/years/2020/receiving.htm': 2020,\n",
    "    'https://www.pro-football-reference.com/years/2021/receiving.htm': 2021,\n",
    "    'https://www.pro-football-reference.com/years/2022/receiving.htm': 2022,\n",
    "    'https://www.pro-football-reference.com/years/2023/receiving.htm': 2023\n",
    "}\n",
    "\n",
    "fetch_data(wr_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Team Offense data\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from lxml import html\n",
    "import pandas as pd\n",
    "\n",
    "def fetch_data(url_list):\n",
    "    # Set up Selenium WebDriver (make sure you have the appropriate driver installed)\n",
    "    driver = webdriver.Chrome()  # or webdriver.Firefox(), etc.\n",
    "\n",
    "    for url in url_list:\n",
    "        \n",
    "        # Navigate to the URL\n",
    "        driver.get(url)\n",
    "\n",
    "        # Wait for the table to load (you might need to adjust the wait time and condition)\n",
    "        WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.ID, \"team_stats\"))\n",
    "        )\n",
    "\n",
    "        # Get the page source and parse it\n",
    "        html_content = driver.page_source\n",
    "        tree = html.fromstring(html_content)\n",
    "\n",
    "        # Scrape the list of columns\n",
    "        columns = tree.xpath('//table[@id=\"team_stats\"]//thead//th/text()')\n",
    "        columns = [c.strip() for c in columns]\n",
    "\n",
    "        # Remove the first five columns\n",
    "        columns = columns[5:]\n",
    "        \n",
    "        # Scrape the list of rows\n",
    "        rows = tree.xpath('//table[@id=\"team_stats\"]//tbody//tr')\n",
    "        data = []\n",
    "\n",
    "        # Extract data from each row\n",
    "        for row in rows:\n",
    "            row_data = []\n",
    "            for r in row.xpath('.//td'):\n",
    "                row_data.append(r.text_content().strip())\n",
    "            # Ensure each row has the same number of columns as the header\n",
    "            while len(row_data) < len(columns):\n",
    "                row_data.append(None)\n",
    "            while len(row_data) > len(columns):\n",
    "                row_data.pop()\n",
    "            data.append(row_data)  # Append the row data to the data list\n",
    "\n",
    "        # Create a DataFrame\n",
    "        df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "        # Save the DataFrame to a CSV file without using any column as an index\n",
    "        df.to_csv(f\"{url_list[url]}_pfr_team_stats.csv\", index=False)\n",
    "\n",
    "    # Close the driver\n",
    "    driver.quit()\n",
    "\n",
    "# URL list\n",
    "team_list = {\n",
    "    'https://www.pro-football-reference.com/years/2012/index.htm': 2012,\n",
    "    'https://www.pro-football-reference.com/years/2013/index.htm': 2013,\n",
    "    'https://www.pro-football-reference.com/years/2014/index.htm': 2014,\n",
    "    'https://www.pro-football-reference.com/years/2015/index.htm': 2015,\n",
    "    'https://www.pro-football-reference.com/years/2016/index.htm': 2016,\n",
    "    'https://www.pro-football-reference.com/years/2017/index.htm': 2017,\n",
    "    'https://www.pro-football-reference.com/years/2018/index.htm': 2018,\n",
    "    'https://www.pro-football-reference.com/years/2019/index.htm': 2019,\n",
    "    'https://www.pro-football-reference.com/years/2020/index.htm': 2020,\n",
    "    'https://www.pro-football-reference.com/years/2021/index.htm': 2021,\n",
    "    'https://www.pro-football-reference.com/years/2022/index.htm': 2022,\n",
    "    'https://www.pro-football-reference.com/years/2023/index.htm': 2023\n",
    "}\n",
    "\n",
    "fetch_data(team_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine data\n",
    "import requests\n",
    "from lxml import html\n",
    "import pandas as pd\n",
    "\n",
    "def fetch_data(url_list):\n",
    "    for url in url_list: \n",
    "        response = requests.get(url)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            # Parse the HTML content\n",
    "            tree = html.fromstring(response.content)\n",
    "\n",
    "            # Correct table ID for the combine stats\n",
    "            table_id = \"combine\"\n",
    "\n",
    "            # Scrape the list of columns\n",
    "            columns = tree.xpath(f'//table[@id=\"{table_id}\"]//thead//tr/th/text()')\n",
    "            columns = [c.strip() for c in columns]\n",
    "\n",
    "            # Scrape the list of rows\n",
    "            rows = tree.xpath(f'//table[@id=\"{table_id}\"]//tbody//tr')\n",
    "            data = []\n",
    "\n",
    "            # Extract data from each row\n",
    "            for row in rows:\n",
    "                row_data = []\n",
    "                for r in row.xpath('.//td | .//th'):\n",
    "                    row_data.append(r.text_content().strip())\n",
    "                # Ensure each row has the same number of columns as the header\n",
    "                while len(row_data) < len(columns):\n",
    "                    row_data.append(None)\n",
    "                while len(row_data) > len(columns):\n",
    "                    row_data.pop()\n",
    "                data.append(row_data)  # Append the row data to the data list\n",
    "\n",
    "            # Create a DataFrame\n",
    "            df = pd.DataFrame(data, columns=columns)\n",
    "            \n",
    "            # Save the DataFrame to a CSV file without using any column as an index\n",
    "            df.to_csv(f\"{url_list[url]}_pfr_combine.csv\", index=False)\n",
    "        else:\n",
    "            print(f\"Failed to fetch the webpage. Status code: {response.status_code}\")\n",
    "\n",
    "# URL list\n",
    "combine_list = {'https://www.pro-football-reference.com/draft/2000-combine.htm': 2000,\n",
    "                'https://www.pro-football-reference.com/draft/2001-combine.htm': 2001,\n",
    "                'https://www.pro-football-reference.com/draft/2002-combine.htm': 2002,\n",
    "                'https://www.pro-football-reference.com/draft/2003-combine.htm': 2003,\n",
    "                'https://www.pro-football-reference.com/draft/2004-combine.htm': 2004,\n",
    "                'https://www.pro-football-reference.com/draft/2005-combine.htm': 2005,\n",
    "                'https://www.pro-football-reference.com/draft/2006-combine.htm': 2006,\n",
    "                'https://www.pro-football-reference.com/draft/2007-combine.htm': 2007,\n",
    "                'https://www.pro-football-reference.com/draft/2008-combine.htm': 2008,\n",
    "                'https://www.pro-football-reference.com/draft/2009-combine.htm': 2009,\n",
    "                'https://www.pro-football-reference.com/draft/2010-combine.htm': 2010,\n",
    "                'https://www.pro-football-reference.com/draft/2011-combine.htm': 2011,\n",
    "                'https://www.pro-football-reference.com/draft/2012-combine.htm': 2012,\n",
    "                'https://www.pro-football-reference.com/draft/2013-combine.htm': 2013,\n",
    "                'https://www.pro-football-reference.com/draft/2014-combine.htm': 2014,\n",
    "                'https://www.pro-football-reference.com/draft/2015-combine.htm': 2015,\n",
    "                'https://www.pro-football-reference.com/draft/2016-combine.htm': 2016,\n",
    "                'https://www.pro-football-reference.com/draft/2017-combine.htm': 2017,\n",
    "                'https://www.pro-football-reference.com/draft/2018-combine.htm': 2018,\n",
    "                'https://www.pro-football-reference.com/draft/2019-combine.htm': 2019,\n",
    "                'https://www.pro-football-reference.com/draft/2020-combine.htm': 2020,\n",
    "                'https://www.pro-football-reference.com/draft/2021-combine.htm': 2021,\n",
    "                'https://www.pro-football-reference.com/draft/2022-combine.htm': 2022,\n",
    "                'https://www.pro-football-reference.com/draft/2023-combine.htm': 2023\n",
    "}\n",
    "\n",
    "fetch_data(combine_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>Year\\nSigned</th>\n",
       "      <th>Years</th>\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "      <th>APY</th>\n",
       "      <th>Guaranteed</th>\n",
       "      <th></th>\n",
       "      <th>APY as % Of\\nCap At Signing</th>\n",
       "      <th></th>\n",
       "      <th>Inflated\\nValue</th>\n",
       "      <th>Inflated\\nAPY</th>\n",
       "      <th>Inflated\\nGuaranteed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Joe Burrow</td>\n",
       "      <td>Bengals</td>\n",
       "      <td>2023</td>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "      <td>$275,000,000</td>\n",
       "      <td>$55,000,000</td>\n",
       "      <td>$219,010,000</td>\n",
       "      <td></td>\n",
       "      <td>24.5%</td>\n",
       "      <td></td>\n",
       "      <td>$312,433,274</td>\n",
       "      <td>$62,486,655</td>\n",
       "      <td>$248,821,859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aaron Rodgers</td>\n",
       "      <td>GB/NYJ</td>\n",
       "      <td>2022</td>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "      <td>$150,815,000</td>\n",
       "      <td>$50,271,667</td>\n",
       "      <td>$150,665,000</td>\n",
       "      <td></td>\n",
       "      <td>24.1%</td>\n",
       "      <td></td>\n",
       "      <td>$185,005,528</td>\n",
       "      <td>$61,668,510</td>\n",
       "      <td>$184,821,523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Josh Allen</td>\n",
       "      <td>Bills</td>\n",
       "      <td>2021</td>\n",
       "      <td>6</td>\n",
       "      <td></td>\n",
       "      <td>$258,000,000</td>\n",
       "      <td>$43,000,000</td>\n",
       "      <td>$150,000,000</td>\n",
       "      <td></td>\n",
       "      <td>23.6%</td>\n",
       "      <td></td>\n",
       "      <td>$361,058,630</td>\n",
       "      <td>$60,176,438</td>\n",
       "      <td>$209,917,808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Russell Wilson</td>\n",
       "      <td>Broncos</td>\n",
       "      <td>2022</td>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "      <td>$245,000,000</td>\n",
       "      <td>$49,000,000</td>\n",
       "      <td>$165,000,000</td>\n",
       "      <td></td>\n",
       "      <td>23.5%</td>\n",
       "      <td></td>\n",
       "      <td>$300,542,747</td>\n",
       "      <td>$60,108,549</td>\n",
       "      <td>$202,406,340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dak Prescott</td>\n",
       "      <td>Cowboys</td>\n",
       "      <td>2024</td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>$240,000,000</td>\n",
       "      <td>$60,000,000</td>\n",
       "      <td>$231,000,000</td>\n",
       "      <td></td>\n",
       "      <td>23.5%</td>\n",
       "      <td></td>\n",
       "      <td>$240,000,000</td>\n",
       "      <td>$60,000,000</td>\n",
       "      <td>$231,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1831</th>\n",
       "      <td>Steve Young</td>\n",
       "      <td>49ers</td>\n",
       "      <td>1991</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>$4,480,000</td>\n",
       "      <td>$2,240,000</td>\n",
       "      <td>$0</td>\n",
       "      <td></td>\n",
       "      <td>0.0%</td>\n",
       "      <td></td>\n",
       "      <td>$0</td>\n",
       "      <td>$0</td>\n",
       "      <td>$0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1832</th>\n",
       "      <td>Brady Quinn</td>\n",
       "      <td>Rams</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>$855,000</td>\n",
       "      <td>$855,000</td>\n",
       "      <td>$0</td>\n",
       "      <td></td>\n",
       "      <td>0.0%</td>\n",
       "      <td></td>\n",
       "      <td>$0</td>\n",
       "      <td>$0</td>\n",
       "      <td>$0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1833</th>\n",
       "      <td>Jon Kitna</td>\n",
       "      <td>Cowboys</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>$940,000</td>\n",
       "      <td>$940,000</td>\n",
       "      <td>$0</td>\n",
       "      <td></td>\n",
       "      <td>0.0%</td>\n",
       "      <td></td>\n",
       "      <td>$0</td>\n",
       "      <td>$0</td>\n",
       "      <td>$0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1834</th>\n",
       "      <td>Connor Halliday</td>\n",
       "      <td>Commanders</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td>$1,582,500</td>\n",
       "      <td>$527,500</td>\n",
       "      <td>$0</td>\n",
       "      <td></td>\n",
       "      <td>0.0%</td>\n",
       "      <td></td>\n",
       "      <td>$0</td>\n",
       "      <td>$0</td>\n",
       "      <td>$0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1835</th>\n",
       "      <td>Jerry Lovelocke</td>\n",
       "      <td>Ravens</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td>$1,580,000</td>\n",
       "      <td>$526,667</td>\n",
       "      <td>$0</td>\n",
       "      <td></td>\n",
       "      <td>0.0%</td>\n",
       "      <td></td>\n",
       "      <td>$0</td>\n",
       "      <td>$0</td>\n",
       "      <td>$0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1836 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Player        Team Year\\nSigned Years            Value  \\\n",
       "0          Joe Burrow     Bengals         2023     5     $275,000,000   \n",
       "1       Aaron Rodgers      GB/NYJ         2022     5     $150,815,000   \n",
       "2          Josh Allen       Bills         2021     6     $258,000,000   \n",
       "3      Russell Wilson     Broncos         2022     5     $245,000,000   \n",
       "4        Dak Prescott     Cowboys         2024     4     $240,000,000   \n",
       "...               ...         ...          ...   ... ..           ...   \n",
       "1831      Steve Young       49ers         1991     2       $4,480,000   \n",
       "1832      Brady Quinn        Rams            0     1         $855,000   \n",
       "1833        Jon Kitna     Cowboys            0     1         $940,000   \n",
       "1834  Connor Halliday  Commanders            0     3       $1,582,500   \n",
       "1835  Jerry Lovelocke      Ravens            0     3       $1,580,000   \n",
       "\n",
       "              APY    Guaranteed    APY as % Of\\nCap At Signing     \\\n",
       "0     $55,000,000  $219,010,000                          24.5%      \n",
       "1     $50,271,667  $150,665,000                          24.1%      \n",
       "2     $43,000,000  $150,000,000                          23.6%      \n",
       "3     $49,000,000  $165,000,000                          23.5%      \n",
       "4     $60,000,000  $231,000,000                          23.5%      \n",
       "...           ...           ... ..                         ... ..   \n",
       "1831   $2,240,000            $0                           0.0%      \n",
       "1832     $855,000            $0                           0.0%      \n",
       "1833     $940,000            $0                           0.0%      \n",
       "1834     $527,500            $0                           0.0%      \n",
       "1835     $526,667            $0                           0.0%      \n",
       "\n",
       "     Inflated\\nValue Inflated\\nAPY Inflated\\nGuaranteed  \n",
       "0       $312,433,274   $62,486,655         $248,821,859  \n",
       "1       $185,005,528   $61,668,510         $184,821,523  \n",
       "2       $361,058,630   $60,176,438         $209,917,808  \n",
       "3       $300,542,747   $60,108,549         $202,406,340  \n",
       "4       $240,000,000   $60,000,000         $231,000,000  \n",
       "...              ...           ...                  ...  \n",
       "1831              $0            $0                   $0  \n",
       "1832              $0            $0                   $0  \n",
       "1833              $0            $0                   $0  \n",
       "1834              $0            $0                   $0  \n",
       "1835              $0            $0                   $0  \n",
       "\n",
       "[1836 rows x 14 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import pandas as pd\n",
    "\n",
    "def scrape_table(url, output_csv='output.csv'):\n",
    "    \"\"\"\n",
    "    Scrape the main table from the given URL and save it to a CSV file.\n",
    "\n",
    "    Parameters:\n",
    "    url (str): The URL of the webpage to scrape.\n",
    "    output_csv (str): The name of the output CSV file. Default is 'output.csv'.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: The scraped data as a pandas DataFrame.\n",
    "    \"\"\"\n",
    "    # Step 1: Set up Selenium and open the webpage\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument('--headless')  # Run in headless mode\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "    driver.get(url)\n",
    "\n",
    "    # Step 2: Wait for the main table to be present\n",
    "    wait = WebDriverWait(driver, 10)\n",
    "    table = wait.until(EC.presence_of_element_located((By.TAG_NAME, 'table')))\n",
    "\n",
    "    # Step 3: Extract the table headers\n",
    "    headers = [header.text.strip() for header in table.find_elements(By.TAG_NAME, 'th')]\n",
    "\n",
    "    # Step 4: Extract the table rows\n",
    "    rows = []\n",
    "    for row in table.find_elements(By.TAG_NAME, 'tr')[1:]:  # Skip the header row\n",
    "        cells = row.find_elements(By.TAG_NAME, 'td')\n",
    "        row_data = [cell.text.strip() for cell in cells]\n",
    "        rows.append(row_data)\n",
    "\n",
    "    # Step 5: Create a DataFrame\n",
    "    df = pd.DataFrame(rows, columns=headers)\n",
    "\n",
    "    # Step 6: Optionally, save the DataFrame to a CSV file\n",
    "    df.to_csv(output_csv, index=False)\n",
    "\n",
    "    # Close the browser\n",
    "    driver.quit()\n",
    "\n",
    "    return df\n",
    "\n",
    "# Example usage\n",
    "scrape_table(url=\"https://overthecap.com/contract-history/tight-end\", output_csv='tight_end_contracts.csv')\n",
    "scrape_table(url=\"https://overthecap.com/contract-history/wide-receiver\", output_csv='wide_receiver_contracts.csv')\n",
    "scrape_table(url=\"https://overthecap.com/contract-history/running-back\", output_csv='running_back_contracts.csv')\n",
    "scrape_table(url=\"https://overthecap.com/contract-history/quarterback\", output_csv='quarterback_contracts.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Player   Age   Tm Pos     G    GS    Cmp    Att  Cmp%     Yds  ...  \\\n",
      "0  Drew Brees  33.0  NOR  QB  16.0  16.0  422.0  670.0  63.0  5177.0  ...   \n",
      "\n",
      "   NY/A  ANY/A  4QC  GWD  Wins  ProBowl  AllPro  MVP  Passing_Points  Year  \n",
      "0  7.17   7.17  1.0  2.0     7        1       0    0          341.08  2012  \n",
      "\n",
      "[1 rows x 36 columns]\n",
      "Index(['Player', 'Age', 'Tm', 'Pos', 'G', 'GS', 'Cmp', 'Att', 'Cmp%', 'Yds',\n",
      "       'TD', 'TD%', 'Int', 'Int%', '1D', 'Succ%', 'Lng', 'Y/A', 'AY/A', 'Y/C',\n",
      "       'Y/G', 'Rate', 'QBR', 'Sk', 'Sack_Yds', 'Sk%', 'NY/A', 'ANY/A', '4QC',\n",
      "       'GWD', 'Wins', 'ProBowl', 'AllPro', 'MVP', 'Passing_Points', 'Year'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Quarterback cleaning\n",
    "passes = {}\n",
    "for year in range(2012, 2024):\n",
    "    passes[year] = pd.read_csv(f'{year}_pfr_passing.csv')\n",
    "\n",
    "# Cleaning\n",
    "for year in range(2012, 2024):\n",
    "    # Change 'Team' to 'Tm'\n",
    "    passes[year] = passes[year].rename(columns={'Team': 'Tm'})\n",
    "    # Change Yds.1 to Rush_Yds\n",
    "    passes[year] = passes[year].rename(columns={'Yds.1': 'Sack_Yds'})\n",
    "    # Split QBrec into Wins and Losses and ties\n",
    "    passes[year][['Wins', 'Losses', 'Ties']] = passes[year]['QBrec'].str.split('-', expand=True)\n",
    "    passes[year] = passes[year].drop(columns=['QBrec', 'Losses', 'Ties'])\n",
    "    # Fill NaN values in Awards column with an empty string\n",
    "    passes[year]['Awards'] = passes[year]['Awards'].fillna('')\n",
    "    # New Column ProBowl which is 1 if 'PB' is in Awards column\n",
    "    passes[year]['ProBowl'] = passes[year]['Awards'].str.contains('PB').astype(int)\n",
    "    # New Column AllPro which is 1 if 'AP' is in Awards column\n",
    "    passes[year]['AllPro'] = passes[year]['Awards'].str.contains('AP').astype(int)\n",
    "    # New column MVP which is 1 if 'MVP' is in Awards column\n",
    "    passes[year]['MVP'] = passes[year]['Awards'].str.contains('MVP').astype(int)\n",
    "    # Drop Awards\n",
    "    passes[year] = passes[year].drop(columns=['Awards'])\n",
    "    # New column Passing_Points which is Yds*0.04 + TD*4 - Int*2\n",
    "    passes[year]['Passing_Points'] = passes[year]['Yds'].astype(float)*0.04 + passes[year]['TD'].astype(float)*4 - passes[year]['Int'].astype(float)*2\n",
    "    # New column Year\n",
    "    passes[year]['Year'] = year\n",
    "\n",
    "# Output\n",
    "print(passes[2012].head(1))\n",
    "print(passes[2012].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Player   Tm  Age Pos   G  GS  Tgt  Rec Ctch%   Yds  ...  Succ%  \\\n",
      "0  Calvin Johnson  DET   27  WR  16  16  204  122  59.8  1964  ...   55.4   \n",
      "\n",
      "   Lng  Y/Tgt  R/G    Y/G  Fmb  AllPro  ProBowl  Receiving_Points  Year  \n",
      "0   53    9.6  7.6  122.8    3       1        1             287.4  2012  \n",
      "\n",
      "[1 rows x 23 columns]\n",
      "Index(['Player', 'Tm', 'Age', 'Pos', 'G', 'GS', 'Tgt', 'Rec', 'Ctch%', 'Yds',\n",
      "       'Y/R', 'TD', '1D', 'Succ%', 'Lng', 'Y/Tgt', 'R/G', 'Y/G', 'Fmb',\n",
      "       'AllPro', 'ProBowl', 'Receiving_Points', 'Year'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Receiving cleaning\n",
    "recs = {}\n",
    "for year in range(2012, 2024):\n",
    "    recs[year] = pd.read_csv(f'{year}_pfr_receiving.csv')\n",
    "\n",
    "# Cleaning\n",
    "for year in range(2012, 2024):\n",
    "    # Drop 'Rk' column\n",
    "    recs[year].drop(columns=['Rk'], inplace=True)\n",
    "    recs[year] = recs[year].drop(columns=['Player-additional'])\n",
    "    # New column AllPro which is 1 if + is in Player column\n",
    "    recs[year]['AllPro'] = recs[year]['Player'].str.contains('\\+').astype(int)\n",
    "    # New column ProBowl which is 1 if * is in Player column\n",
    "    recs[year]['ProBowl'] = recs[year]['Player'].str.contains('\\*').astype(int)\n",
    "    # Remove + and * from Player column\n",
    "    recs[year]['Player'] = recs[year]['Player'].str.replace('+', '')\n",
    "    recs[year]['Player'] = recs[year]['Player'].str.replace('*', '')\n",
    "    # Remove % from Ctch% column\n",
    "    recs[year]['Ctch%'] = recs[year]['Ctch%'].str.replace('%', '')\n",
    "    # New column Receiving_Points which is Rec*0.5 + Yds*0.1 + TD*6\n",
    "    recs[year]['Receiving_Points'] = recs[year]['Rec'].astype(int)*0.5 + recs[year]['Yds'].astype(int)*0.1 + recs[year]['TD'].astype(int)*6\n",
    "    # New column Year\n",
    "    recs[year]['Year'] = year\n",
    "\n",
    "# Output\n",
    "print(recs[2012].head(1))\n",
    "print(recs[2012].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Player   Tm  Age Pos   G  GS  Att   Yds  TD  1D  Lng  Y/A   Y/G  Fmb  \\\n",
      "0  Arian Foster  HOU   26  RB  16  16  351  1424  15  78   46  4.1  89.0    3   \n",
      "\n",
      "   AllPro  ProBowl  Rushing_Points  Year  \n",
      "0       0        1           226.4  2012  \n",
      "Index(['Player', 'Tm', 'Age', 'Pos', 'G', 'GS', 'Att', 'Yds', 'TD', '1D',\n",
      "       'Lng', 'Y/A', 'Y/G', 'Fmb', 'AllPro', 'ProBowl', 'Rushing_Points',\n",
      "       'Year'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Rushing cleaning\n",
    "rushes = {}\n",
    "for year in range(2012, 2024):\n",
    "    rushes[year] = pd.read_csv(f'{year}_pfr_rushing.csv')\n",
    "\n",
    "# Cleaning\n",
    "for year in range(2012, 2024):\n",
    "    # Drop 'Rk' column\n",
    "    rushes[year].drop(columns=['Rk'], inplace=True)\n",
    "    # Rename -9999 to Player-additional column\n",
    "    rushes[year] = rushes[year].rename(columns={'-9999': 'Player-additional'})\n",
    "    rushes[year] = rushes[year].drop(columns=['Player-additional'])\n",
    "    # New column AllPro which is 1 if + is in Player column\n",
    "    rushes[year]['AllPro'] = rushes[year]['Player'].str.contains('\\+').astype(int)\n",
    "    # New column ProBowl which is 1 if * is in Player column\n",
    "    rushes[year]['ProBowl'] = rushes[year]['Player'].str.contains('\\*').astype(int)\n",
    "    # Remove + and * from Player column\n",
    "    rushes[year]['Player'] = rushes[year]['Player'].str.replace('+', '')\n",
    "    rushes[year]['Player'] = rushes[year]['Player'].str.replace('*', '')\n",
    "    # New column Rushing_Points which is Yds*0.1 + TD*6 - Fmb*2\n",
    "    rushes[year]['Rushing_Points'] = rushes[year]['Yds'].astype(int)*0.1 + rushes[year]['TD'].astype(int)*6 - rushes[year]['Fmb'].astype(int)*2\n",
    "    # New column Year\n",
    "    rushes[year]['Year'] = year\n",
    "\n",
    "# Output   \n",
    "print(rushes[2012].head(1))\n",
    "print(rushes[2012].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary for Team Names\n",
    "team_names = {\n",
    "    'Arizona Cardinals': 'ARI',\n",
    "    'Atlanta Falcons': 'ATL',\n",
    "    'Baltimore Ravens': 'BAL',\n",
    "    'Buffalo Bills': 'BUF',\n",
    "    'Carolina Panthers': 'CAR',\n",
    "    'Chicago Bears': 'CHI',\n",
    "    'Cincinnati Bengals': 'CIN',\n",
    "    'Cleveland Browns': 'CLE',\n",
    "    'Dallas Cowboys': 'DAL',\n",
    "    'Denver Broncos': 'DEN',\n",
    "    'Detroit Lions': 'DET',\n",
    "    'Green Bay Packers': 'GNB',\n",
    "    'Houston Texans': 'HOU',\n",
    "    'Indianapolis Colts': 'IND',\n",
    "    'Jacksonville Jaguars': 'JAX',\n",
    "    'Kansas City Chiefs': 'KAN',\n",
    "    'Las Vegas Raiders': 'LVR',\n",
    "    'Los Angeles Chargers': 'LAC',\n",
    "    'Los Angeles Rams': 'LAR',\n",
    "    'Miami Dolphins': 'MIA',\n",
    "    'Minnesota Vikings': 'MIN',\n",
    "    'New England Patriots': 'NWE',\n",
    "    'New Orleans Saints': 'NOR',\n",
    "    'New York Giants': 'NYG',\n",
    "    'New York Jets': 'NYJ',\n",
    "    'Oakland Raiders': 'OAK',\n",
    "    'Philadelphia Eagles': 'PHI',\n",
    "    'Pittsburgh Steelers': 'PIT',\n",
    "    'St. Louis Rams': 'STL',\n",
    "    'San Francisco 49ers': 'SFO',\n",
    "    'San Diego Chargers': 'SDG',\n",
    "    'Seattle Seahawks': 'SEA',\n",
    "    'Tampa Bay Buccaneers': 'TAM',\n",
    "    'Tennessee Titans': 'TEN',\n",
    "    'Washington Football Team': 'WAS',\n",
    "    'Washington Redskins': 'WAS'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Team_Name   G   PF   Yds   Ply  Y/P  TO  FL  1stD  Cmp  ...  \\\n",
      "0  New England Patriots  16  557  6846  1191  5.7  16   7   444  402  ...   \n",
      "\n",
      "   YdsPer_Rush  1stD_Rush  Pen  Yds_Pen  1stPy   Sc%  TO%     EXP   Tm  Year  \n",
      "0          4.2        151   97      840     37  48.1  8.1  118.97  NWE  2012  \n",
      "\n",
      "[1 rows x 29 columns]\n",
      "Index(['Team_Name', 'G', 'PF', 'Yds', 'Ply', 'Y/P', 'TO', 'FL', '1stD', 'Cmp',\n",
      "       'Att_Pass', 'Yds_Pass', 'TD_Pass', 'Int', 'NY/A', '1stD_Pass',\n",
      "       'Att_Rush', 'Yds_Rush', 'TD_Rush', 'YdsPer_Rush', '1stD_Rush', 'Pen',\n",
      "       'Yds_Pen', '1stPy', 'Sc%', 'TO%', 'EXP', 'Tm', 'Year'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Team Offense cleaning\n",
    "teams = {}\n",
    "\n",
    "for year in range(2012, 2024):\n",
    "    teams[year] = pd.read_csv(f'{year}_pfr_team_stats.csv')\n",
    "\n",
    "# Cleaning\n",
    "for year in range(2012, 2024):\n",
    "    # Rename 1stD.1 to 1stD_Pass\n",
    "    teams[year] = teams[year].rename(columns={'Yds.1': 'Yds_Pass'})\n",
    "    teams[year] = teams[year].rename(columns={'1stD.1': '1stD_Pass'})\n",
    "    teams[year] = teams[year].rename(columns={'TD': 'TD_Pass'})\n",
    "    teams[year] = teams[year].rename(columns={'Att': 'Att_Pass'})\n",
    "    # Rename 1stD.2 to 1stD_Rush\n",
    "    teams[year] = teams[year].rename(columns={'Att.1': 'Att_Rush'})\n",
    "    teams[year] = teams[year].rename(columns={'Yds.2': 'Yds_Rush'})\n",
    "    teams[year] = teams[year].rename(columns={'TD.1': 'TD_Rush'})\n",
    "    teams[year] = teams[year].rename(columns={'1stD.2': '1stD_Rush'})\n",
    "    teams[year] = teams[year].rename(columns={'Y/A': 'YdsPer_Rush'})\n",
    "    # Rename Yds.3 to Yds_Pen\n",
    "    teams[year] = teams[year].rename(columns={'Yds.3': 'Yds_Pen'})\n",
    "    # Rename Tm to Team_Name\n",
    "    teams[year] = teams[year].rename(columns={'Tm': 'Team_Name'})\n",
    "    # New column that uses team_names dictionary to convert Team_Name to Tm\n",
    "    teams[year]['Tm'] = teams[year]['Team_Name'].map(team_names)\n",
    "    # New column Year\n",
    "    teams[year]['Year'] = year\n",
    "\n",
    "# Output\n",
    "print(teams[2012].head(1))\n",
    "print(teams[2012].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'team_names' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 33\u001b[0m\n\u001b[0;32m     31\u001b[0m combines[year][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTeam_Name\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m combines[year][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTeam_Name\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# New column that uses team_names dictionary to convert Team_Name to Tm for non-empty values\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m combines[year][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTm\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m combines[year][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTeam_Name\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmap(team_names)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# Convert  Wt  40yd Vertical Bench Broad Jump 3Cone Shuttle  Height to numeric\u001b[39;00m\n\u001b[0;32m     35\u001b[0m combines[year][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWt\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_numeric(combines[year][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWt\u001b[39m\u001b[38;5;124m'\u001b[39m], errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'team_names' is not defined"
     ]
    }
   ],
   "source": [
    "# Combine cleaning\n",
    "combines = {}\n",
    "for year in range(2000, 2024):\n",
    "    combines[year] = pd.read_csv(f'{year}_pfr_combine.csv')\n",
    "\n",
    "# Cleaning\n",
    "for year in range(2000, 2024):\n",
    "    # Remove College column\n",
    "    combines[year] = combines[year].drop(columns=['College'])\n",
    "    # Split Ht into Feet and Inches at the dash\n",
    "    combines[year][['Feet', 'Inches']] = combines[year]['Ht'].str.split('-', expand=True)\n",
    "    # Replace None and nan with 0 in the Inches column\n",
    "    combines[year]['Inches'] = combines[year]['Inches'].replace([None, np.nan], '0')\n",
    "    combines[year]['Feet'] = combines[year]['Feet'].replace(['Ht', np.nan], '5')\n",
    "    # Convert both columns to integers\n",
    "    combines[year]['Feet'] = combines[year]['Feet'].astype(int)\n",
    "    combines[year]['Inches'] = combines[year]['Inches'].astype(int)\n",
    "    # New column Height which is the sum of Feet and Inches\n",
    "    combines[year]['Height'] = combines[year]['Feet'].astype(int) * 12 + combines[year]['Inches'].astype(int)\n",
    "    # Drop Ht, Feet, Inches\n",
    "    combines[year] = combines[year].drop(columns=['Ht', 'Feet', 'Inches'])\n",
    "    # Split Drafted (tm/rnd/yr) into Tm, Round, Pick, and Year\n",
    "    combines[year][['Tm', 'Round', 'Pick', 'Year']] = combines[year]['Drafted (tm/rnd/yr)'].str.split('/', expand=True)\n",
    "    combines[year] = combines[year].drop(columns=['Drafted (tm/rnd/yr)'])\n",
    "    # Split pick into Pick and letters at the first letter\n",
    "    combines[year][['Pick', 'Let', 'letter', 'extra', 'bub']] = combines[year]['Pick'].str.split('([A-Za-z]+)', expand=True)\n",
    "    combines[year] = combines[year].drop(columns=['Let', 'letter', 'extra', 'bub'])\n",
    "    # Rename Tm to Team_Name\n",
    "    combines[year] = combines[year].rename(columns={'Tm': 'Team_Name'})\n",
    "    # Strip whitespace from Team_Name\n",
    "    combines[year]['Team_Name'] = combines[year]['Team_Name'].str.strip()\n",
    "    # New column that uses team_names dictionary to convert Team_Name to Tm for non-empty values\n",
    "    combines[year]['Tm'] = combines[year]['Team_Name'].map(team_names)\n",
    "    # Convert  Wt  40yd Vertical Bench Broad Jump 3Cone Shuttle  Height to numeric\n",
    "    combines[year]['Wt'] = pd.to_numeric(combines[year]['Wt'], errors='coerce')\n",
    "    combines[year]['40yd'] = pd.to_numeric(combines[year]['40yd'], errors='coerce')\n",
    "    combines[year]['Vertical'] = pd.to_numeric(combines[year]['Vertical'], errors='coerce')\n",
    "    combines[year]['Bench'] = pd.to_numeric(combines[year]['Bench'], errors='coerce')\n",
    "    combines[year]['Broad Jump'] = pd.to_numeric(combines[year]['Broad Jump'], errors='coerce')\n",
    "    combines[year]['3Cone'] = pd.to_numeric(combines[year]['3Cone'], errors='coerce')\n",
    "    combines[year]['Shuttle'] = pd.to_numeric(combines[year]['Shuttle'], errors='coerce')\n",
    "    combines[year]['Height'] = pd.to_numeric(combines[year]['Height'], errors='coerce')\n",
    "\n",
    "# Output\n",
    "print(combines[2000].head(3))\n",
    "print(combines[2000].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salary cleaning\n",
    "def salary_cleaning(df):\n",
    "    # Rename columns\n",
    "    df = df.rename(columns={'Year\\nSigned': 'Year', 'Inflated\\nGuaranteed': 'Inflated_Guaranteed', \n",
    "                                        'Years': 'Length'})\n",
    "    df = df[['Player', 'Year', 'Length', 'Inflated_Guaranteed']]\n",
    "\n",
    "    # Ensure columns are of string type before using str accessor\n",
    "    df['Inflated_Guaranteed'] = df['Inflated_Guaranteed'].astype(str)\n",
    "\n",
    "    # Remove characters\n",
    "    df['Inflated_Guaranteed'] = df['Inflated_Guaranteed'].str.replace('$', '', regex=False)\n",
    "\n",
    "    # Replace nan with 1\n",
    "    df['Length'] = df['Length'].fillna(1)\n",
    "\n",
    "    # Clean data types\n",
    "    df['Inflated_Guaranteed'] = df['Inflated_Guaranteed'].str.replace(',', '')\n",
    "    df['Inflated_Guaranteed'] = df['Inflated_Guaranteed'].astype(int)\n",
    "    df['Year'] = df['Year'].astype(int)\n",
    "    df['Length'] = df['Length'].astype(int)\n",
    "\n",
    "    # Group by year, player, years, for inflated guaranteed\n",
    "    df = df.groupby(['Player', 'Year', 'Length'])['Inflated_Guaranteed'].mean().reset_index()\n",
    "\n",
    "    # New column: list of integers between year and year+length\n",
    "    df['Contract_Years'] = df.apply(lambda x: list(range(x['Year'], x['Year'] + x['Length'])), axis=1)\n",
    "\n",
    "    # Expand contract years to columns, value is inflated guaranteed\n",
    "    df = df.explode('Contract_Years')\n",
    "    df['Contract_Years'] = df['Contract_Years'].astype(int)\n",
    "\n",
    "    # Sort by Player, Year, and Years in descending order\n",
    "    df = df.sort_values(by=['Player', 'Year', 'Contract_Years'], ascending=[True, False, False])\n",
    "\n",
    "    # Drop duplicates, keeping the first occurrence (which has the higher Year and Years)\n",
    "    df = df.drop_duplicates(subset=['Player', 'Contract_Years'], keep='first')\n",
    "\n",
    "    return df\n",
    "\n",
    "# Clean salary data\n",
    "qb_salary = salary_cleaning(pd.read_csv('quarterback_contracts.csv'))\n",
    "rb_salary = salary_cleaning(pd.read_csv('running_back_contracts.csv'))\n",
    "wr_salary = salary_cleaning(pd.read_csv('wide_receiver_contracts.csv'))\n",
    "te_salary = salary_cleaning(pd.read_csv('tight_end_contracts.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Year</th>\n",
       "      <th>Length</th>\n",
       "      <th>Inflated_Guaranteed</th>\n",
       "      <th>Contract_Years</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A.J. McCarron</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A.J. McCarron</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>192425.0</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A.J. McCarron</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>4832240.0</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A.J. McCarron</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>3392667.0</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A.J. McCarron</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>8647856.0</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A.J. McCarron</td>\n",
       "      <td>2014</td>\n",
       "      <td>4</td>\n",
       "      <td>348826.0</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A.J. McCarron</td>\n",
       "      <td>2014</td>\n",
       "      <td>4</td>\n",
       "      <td>348826.0</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A.J. McCarron</td>\n",
       "      <td>2014</td>\n",
       "      <td>4</td>\n",
       "      <td>348826.0</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A.J. McCarron</td>\n",
       "      <td>2014</td>\n",
       "      <td>4</td>\n",
       "      <td>348826.0</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Aaron Murray</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Aaron Murray</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Aaron Murray</td>\n",
       "      <td>2014</td>\n",
       "      <td>4</td>\n",
       "      <td>350309.0</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Aaron Murray</td>\n",
       "      <td>2014</td>\n",
       "      <td>4</td>\n",
       "      <td>350309.0</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Aaron Rodgers</td>\n",
       "      <td>2023</td>\n",
       "      <td>3</td>\n",
       "      <td>85209075.0</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Aaron Rodgers</td>\n",
       "      <td>2023</td>\n",
       "      <td>3</td>\n",
       "      <td>85209075.0</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Aaron Rodgers</td>\n",
       "      <td>2023</td>\n",
       "      <td>3</td>\n",
       "      <td>85209075.0</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Aaron Rodgers</td>\n",
       "      <td>2022</td>\n",
       "      <td>5</td>\n",
       "      <td>184821523.0</td>\n",
       "      <td>2026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Aaron Rodgers</td>\n",
       "      <td>2022</td>\n",
       "      <td>5</td>\n",
       "      <td>184821523.0</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Aaron Rodgers</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>141536569.0</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Aaron Rodgers</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>141536569.0</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Player  Year  Length  Inflated_Guaranteed  Contract_Years\n",
       "5   A.J. McCarron  2023       1                  0.0            2023\n",
       "4   A.J. McCarron  2021       1             192425.0            2021\n",
       "3   A.J. McCarron  2020       1            4832240.0            2020\n",
       "2   A.J. McCarron  2019       1            3392667.0            2019\n",
       "1   A.J. McCarron  2018       2            8647856.0            2018\n",
       "0   A.J. McCarron  2014       4             348826.0            2017\n",
       "0   A.J. McCarron  2014       4             348826.0            2016\n",
       "0   A.J. McCarron  2014       4             348826.0            2015\n",
       "0   A.J. McCarron  2014       4             348826.0            2014\n",
       "8    Aaron Murray  2017       1                  0.0            2017\n",
       "7    Aaron Murray  2016       1                  0.0            2016\n",
       "6    Aaron Murray  2014       4             350309.0            2015\n",
       "6    Aaron Murray  2014       4             350309.0            2014\n",
       "14  Aaron Rodgers  2023       3           85209075.0            2025\n",
       "14  Aaron Rodgers  2023       3           85209075.0            2024\n",
       "14  Aaron Rodgers  2023       3           85209075.0            2023\n",
       "13  Aaron Rodgers  2022       5          184821523.0            2026\n",
       "13  Aaron Rodgers  2022       5          184821523.0            2022\n",
       "12  Aaron Rodgers  2018       4          141536569.0            2021\n",
       "12  Aaron Rodgers  2018       4          141536569.0            2020"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qb_salary.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine passing data\n",
    "qb_data = pd.concat(passes.values(), ignore_index=True)\n",
    "# Combine receiving data\n",
    "rec_data = pd.concat(recs.values(), ignore_index=True)\n",
    "# Combine rushing data\n",
    "rush_data = pd.concat(rushes.values(), ignore_index=True)\n",
    "# Combine team offense data\n",
    "team_data = pd.concat(teams.values(), ignore_index=True)\n",
    "# Combine combine data\n",
    "combine_data = pd.concat(combines.values(), ignore_index=True)\n",
    "# Combine Salary data\n",
    "salary_data = pd.concat([qb_salary, rb_salary, wr_salary, te_salary], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save qb_data\n",
    "qb_data.to_csv('gross_pfr_passing.csv', index=False)\n",
    "# Save rec_data\n",
    "rec_data.to_csv('gross_pfr_receiving.csv', index=False)\n",
    "# Save rush_data\n",
    "rush_data.to_csv('gross_pfr_rushing.csv', index=False)\n",
    "# Save team_data\n",
    "team_data.to_csv('gross_pfr_team_offense.csv', index=False)\n",
    "# Save combine_data\n",
    "combine_data.to_csv('gross_pfr_combine.csv', index=False)\n",
    "# Save salary data\n",
    "salary_data.to_csv('gross_pfr_salary.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
