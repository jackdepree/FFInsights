{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set working directory\n",
    "import os\n",
    "current_dir = os.getcwd()\n",
    "os.chdir(current_dir.replace('\\code', '\\data'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quaterback data\n",
    "import requests\n",
    "from lxml import html\n",
    "import pandas as pd\n",
    "\n",
    "def fetch_data(url_list):\n",
    "    for url in url_list:\n",
    "        # Send a GET request to fetch the webpage content\n",
    "        response = requests.get(url)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            # Parse the HTML content\n",
    "            tree = html.fromstring(response.content)\n",
    "\n",
    "            # Scrape the list of columns\n",
    "            columns = tree.xpath('//table[@id=\"passing\"]//thead//th/text()')\n",
    "            columns = [c.strip() for c in columns]\n",
    "\n",
    "            # Remove the first column\n",
    "            columns = columns[1:]\n",
    "            \n",
    "            # Scrape the list of rows\n",
    "            rows = tree.xpath('//table[@id=\"passing\"]//tbody//tr')\n",
    "            data = []\n",
    "\n",
    "            # Extract data from each row\n",
    "            for row in rows:\n",
    "                row_data = []\n",
    "                for r in row.xpath('.//td'):\n",
    "                    row_data.append(r.text_content().strip())\n",
    "                # Ensure each row has the same number of columns as the header\n",
    "                while len(row_data) < len(columns):\n",
    "                    row_data.append(None)\n",
    "                while len(row_data) > len(columns):\n",
    "                    row_data.pop()\n",
    "                data.append(row_data)  # Append the row data to the data list\n",
    "\n",
    "            # Create a DataFrame\n",
    "            df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "            # Save the DataFrame to a CSV file without using any column as an index\n",
    "            df.to_csv(f\"{url_list[url]}_pfr_passing.csv\", index=False)\n",
    "        else:\n",
    "            print(f\"Failed to fetch the webpage. Status code: {response.status_code}\")\n",
    "\n",
    "# URL list\n",
    "qb_list = {\n",
    "    'https://www.pro-football-reference.com/years/2012/passing.htm': 2012, \n",
    "    'https://www.pro-football-reference.com/years/2013/passing.htm': 2013,\n",
    "    'https://www.pro-football-reference.com/years/2014/passing.htm': 2014,\n",
    "    'https://www.pro-football-reference.com/years/2015/passing.htm': 2015,\n",
    "    'https://www.pro-football-reference.com/years/2016/passing.htm': 2016,\n",
    "    'https://www.pro-football-reference.com/years/2017/passing.htm': 2017,\n",
    "    'https://www.pro-football-reference.com/years/2018/passing.htm': 2018,\n",
    "    'https://www.pro-football-reference.com/years/2019/passing.htm': 2019,\n",
    "    'https://www.pro-football-reference.com/years/2020/passing.htm': 2020,\n",
    "    'https://www.pro-football-reference.com/years/2021/passing.htm': 2021,\n",
    "    'https://www.pro-football-reference.com/years/2022/passing.htm': 2022,\n",
    "    'https://www.pro-football-reference.com/years/2023/passing.htm': 2023\n",
    "}\n",
    "\n",
    "fetch_data(qb_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Age</th>\n",
       "      <th>Team</th>\n",
       "      <th>Pos</th>\n",
       "      <th>G</th>\n",
       "      <th>GS</th>\n",
       "      <th>QBrec</th>\n",
       "      <th>Cmp</th>\n",
       "      <th>Att</th>\n",
       "      <th>Cmp%</th>\n",
       "      <th>...</th>\n",
       "      <th>Rate</th>\n",
       "      <th>QBR</th>\n",
       "      <th>Sk</th>\n",
       "      <th>Yds.1</th>\n",
       "      <th>Sk%</th>\n",
       "      <th>NY/A</th>\n",
       "      <th>ANY/A</th>\n",
       "      <th>4QC</th>\n",
       "      <th>GWD</th>\n",
       "      <th>Awards</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Drew Brees</td>\n",
       "      <td>33.0</td>\n",
       "      <td>NOR</td>\n",
       "      <td>QB</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>7-9-0</td>\n",
       "      <td>422.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>...</td>\n",
       "      <td>96.3</td>\n",
       "      <td>68.7</td>\n",
       "      <td>26.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>3.74</td>\n",
       "      <td>7.17</td>\n",
       "      <td>7.17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>PB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Matthew Stafford</td>\n",
       "      <td>24.0</td>\n",
       "      <td>DET</td>\n",
       "      <td>QB</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4-12-0</td>\n",
       "      <td>435.0</td>\n",
       "      <td>727.0</td>\n",
       "      <td>59.8</td>\n",
       "      <td>...</td>\n",
       "      <td>79.8</td>\n",
       "      <td>56.1</td>\n",
       "      <td>29.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>3.84</td>\n",
       "      <td>6.29</td>\n",
       "      <td>5.81</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tony Romo</td>\n",
       "      <td>32.0</td>\n",
       "      <td>DAL</td>\n",
       "      <td>QB</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>8-8-0</td>\n",
       "      <td>425.0</td>\n",
       "      <td>648.0</td>\n",
       "      <td>65.6</td>\n",
       "      <td>...</td>\n",
       "      <td>90.5</td>\n",
       "      <td>65.4</td>\n",
       "      <td>36.0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>5.26</td>\n",
       "      <td>6.78</td>\n",
       "      <td>6.35</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tom Brady</td>\n",
       "      <td>35.0</td>\n",
       "      <td>NWE</td>\n",
       "      <td>QB</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>12-4-0</td>\n",
       "      <td>401.0</td>\n",
       "      <td>637.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>...</td>\n",
       "      <td>98.7</td>\n",
       "      <td>76.1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>4.07</td>\n",
       "      <td>7.00</td>\n",
       "      <td>7.48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>PB,AP OPoY-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Matt Ryan</td>\n",
       "      <td>27.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>QB</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>13-3-0</td>\n",
       "      <td>422.0</td>\n",
       "      <td>615.0</td>\n",
       "      <td>68.6</td>\n",
       "      <td>...</td>\n",
       "      <td>99.1</td>\n",
       "      <td>71.6</td>\n",
       "      <td>28.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>4.35</td>\n",
       "      <td>7.01</td>\n",
       "      <td>7.03</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>PB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Player   Age Team Pos     G    GS   QBrec    Cmp    Att  Cmp%  \\\n",
       "0        Drew Brees  33.0  NOR  QB  16.0  16.0   7-9-0  422.0  670.0  63.0   \n",
       "1  Matthew Stafford  24.0  DET  QB  16.0  16.0  4-12-0  435.0  727.0  59.8   \n",
       "2         Tony Romo  32.0  DAL  QB  16.0  16.0   8-8-0  425.0  648.0  65.6   \n",
       "3         Tom Brady  35.0  NWE  QB  16.0  16.0  12-4-0  401.0  637.0  63.0   \n",
       "4         Matt Ryan  27.0  ATL  QB  16.0  16.0  13-3-0  422.0  615.0  68.6   \n",
       "\n",
       "   ...  Rate   QBR    Sk  Yds.1   Sk%  NY/A  ANY/A  4QC  GWD        Awards  \n",
       "0  ...  96.3  68.7  26.0  190.0  3.74  7.17   7.17  1.0  2.0            PB  \n",
       "1  ...  79.8  56.1  29.0  212.0  3.84  6.29   5.81  3.0  3.0           NaN  \n",
       "2  ...  90.5  65.4  36.0  263.0  5.26  6.78   6.35  5.0  5.0           NaN  \n",
       "3  ...  98.7  76.1  27.0  182.0  4.07  7.00   7.48  1.0  2.0  PB,AP OPoY-3  \n",
       "4  ...  99.1  71.6  28.0  210.0  4.35  7.01   7.03  4.0  6.0            PB  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pass_12 = pd.read_csv('2012_pfr_passing.csv')\n",
    "pass_12.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Receiving and Rushing data\n",
    "import requests\n",
    "from lxml import html\n",
    "import pandas as pd\n",
    "\n",
    "def fetch_data(url_list):\n",
    "    for url in url_list:\n",
    "        # Send a GET request to fetch the webpage content\n",
    "        response = requests.get(url)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            # Parse the HTML content\n",
    "            tree = html.fromstring(response.content)\n",
    "\n",
    "            # Scrape the list of columns\n",
    "            columns = tree.xpath('//table[@id=\"passing\"]//thead//th/text()')\n",
    "            columns = [c.strip() for c in columns]\n",
    "            \n",
    "            # Scrape the list of rows\n",
    "            rows = tree.xpath('//table[@id=\"passing\"]//tbody//tr')\n",
    "            data = []\n",
    "\n",
    "            # Extract data from each row\n",
    "            for row in rows:\n",
    "                row_data = []\n",
    "                for r in row.xpath('.//td'):\n",
    "                    row_data.append(r.text_content().strip())\n",
    "                # Ensure each row has the same number of columns as the header\n",
    "                while len(row_data) < len(columns):\n",
    "                    row_data.append(None)\n",
    "                while len(row_data) > len(columns):\n",
    "                    row_data.pop()\n",
    "                data.append(row_data)  # Append the row data to the data list\n",
    "\n",
    "            # Create a DataFrame\n",
    "            df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "            # Save the DataFrame to a CSV file without using any column as an index\n",
    "            df.to_csv(f\"{url_list[url]}_pfr_passing.csv\", index=False)\n",
    "        else:\n",
    "            print(f\"Failed to fetch the webpage. Status code: {response.status_code}\")\n",
    "\n",
    "# URL list\n",
    "rb_list = {\n",
    "    'https://www.pro-football-reference.com/years/2012/rushing.htm': 2012,\n",
    "    'https://www.pro-football-reference.com/years/2013/rushing.htm': 2013,\n",
    "    'https://www.pro-football-reference.com/years/2014/rushing.htm': 2014,\n",
    "    'https://www.pro-football-reference.com/years/2015/rushing.htm': 2015,\n",
    "    'https://www.pro-football-reference.com/years/2016/rushing.htm': 2016,\n",
    "    'https://www.pro-football-reference.com/years/2017/rushing.htm': 2017,\n",
    "    'https://www.pro-football-reference.com/years/2018/rushing.htm': 2018,\n",
    "    'https://www.pro-football-reference.com/years/2019/rushing.htm': 2019,\n",
    "    'https://www.pro-football-reference.com/years/2020/rushing.htm': 2020,\n",
    "    'https://www.pro-football-reference.com/years/2021/rushing.htm': 2021,\n",
    "    'https://www.pro-football-reference.com/years/2022/rushing.htm': 2022,\n",
    "    'https://www.pro-football-reference.com/years/2023/rushing.htm': 2023\n",
    "}\n",
    "\n",
    "# URL list\n",
    "wr_list = {\n",
    "    'https://www.pro-football-reference.com/years/2012/receiving.htm': 2012,\n",
    "    'https://www.pro-football-reference.com/years/2013/receiving.htm': 2013,\n",
    "    'https://www.pro-football-reference.com/years/2014/receiving.htm': 2014,\n",
    "    'https://www.pro-football-reference.com/years/2015/receiving.htm': 2015,\n",
    "    'https://www.pro-football-reference.com/years/2016/receiving.htm': 2016,\n",
    "    'https://www.pro-football-reference.com/years/2017/receiving.htm': 2017,\n",
    "    'https://www.pro-football-reference.com/years/2018/receiving.htm': 2018,\n",
    "    'https://www.pro-football-reference.com/years/2019/receiving.htm': 2019,\n",
    "    'https://www.pro-football-reference.com/years/2020/receiving.htm': 2020,\n",
    "    'https://www.pro-football-reference.com/years/2021/receiving.htm': 2021,\n",
    "    'https://www.pro-football-reference.com/years/2022/receiving.htm': 2022,\n",
    "    'https://www.pro-football-reference.com/years/2023/receiving.htm': 2023\n",
    "}\n",
    "\n",
    "fetch_data(wr_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Team Offense data\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from lxml import html\n",
    "import pandas as pd\n",
    "\n",
    "def fetch_data(url_list):\n",
    "    # Set up Selenium WebDriver (make sure you have the appropriate driver installed)\n",
    "    driver = webdriver.Chrome()  # or webdriver.Firefox(), etc.\n",
    "\n",
    "    for url in url_list:\n",
    "        \n",
    "        # Navigate to the URL\n",
    "        driver.get(url)\n",
    "\n",
    "        # Wait for the table to load (you might need to adjust the wait time and condition)\n",
    "        WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.ID, \"team_stats\"))\n",
    "        )\n",
    "\n",
    "        # Get the page source and parse it\n",
    "        html_content = driver.page_source\n",
    "        tree = html.fromstring(html_content)\n",
    "\n",
    "        # Scrape the list of columns\n",
    "        columns = tree.xpath('//table[@id=\"team_stats\"]//thead//th/text()')\n",
    "        columns = [c.strip() for c in columns]\n",
    "\n",
    "        # Remove the first five columns\n",
    "        columns = columns[5:]\n",
    "        \n",
    "        # Scrape the list of rows\n",
    "        rows = tree.xpath('//table[@id=\"team_stats\"]//tbody//tr')\n",
    "        data = []\n",
    "\n",
    "        # Extract data from each row\n",
    "        for row in rows:\n",
    "            row_data = []\n",
    "            for r in row.xpath('.//td'):\n",
    "                row_data.append(r.text_content().strip())\n",
    "            # Ensure each row has the same number of columns as the header\n",
    "            while len(row_data) < len(columns):\n",
    "                row_data.append(None)\n",
    "            while len(row_data) > len(columns):\n",
    "                row_data.pop()\n",
    "            data.append(row_data)  # Append the row data to the data list\n",
    "\n",
    "        # Create a DataFrame\n",
    "        df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "        # Save the DataFrame to a CSV file without using any column as an index\n",
    "        df.to_csv(f\"{url_list[url]}_pfr_team_stats.csv\", index=False)\n",
    "\n",
    "    # Close the driver\n",
    "    driver.quit()\n",
    "\n",
    "# URL list\n",
    "team_list = {\n",
    "    'https://www.pro-football-reference.com/years/2012/index.htm': 2012,\n",
    "    'https://www.pro-football-reference.com/years/2013/index.htm': 2013,\n",
    "    'https://www.pro-football-reference.com/years/2014/index.htm': 2014,\n",
    "    'https://www.pro-football-reference.com/years/2015/index.htm': 2015,\n",
    "    'https://www.pro-football-reference.com/years/2016/index.htm': 2016,\n",
    "    'https://www.pro-football-reference.com/years/2017/index.htm': 2017,\n",
    "    'https://www.pro-football-reference.com/years/2018/index.htm': 2018,\n",
    "    'https://www.pro-football-reference.com/years/2019/index.htm': 2019,\n",
    "    'https://www.pro-football-reference.com/years/2020/index.htm': 2020,\n",
    "    'https://www.pro-football-reference.com/years/2021/index.htm': 2021,\n",
    "    'https://www.pro-football-reference.com/years/2022/index.htm': 2022,\n",
    "    'https://www.pro-football-reference.com/years/2023/index.htm': 2023\n",
    "}\n",
    "\n",
    "fetch_data(team_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine data\n",
    "import requests\n",
    "from lxml import html\n",
    "import pandas as pd\n",
    "\n",
    "def fetch_data(url_list):\n",
    "    for url in url_list: \n",
    "        response = requests.get(url)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            # Parse the HTML content\n",
    "            tree = html.fromstring(response.content)\n",
    "\n",
    "            # Correct table ID for the combine stats\n",
    "            table_id = \"combine\"\n",
    "\n",
    "            # Scrape the list of columns\n",
    "            columns = tree.xpath(f'//table[@id=\"{table_id}\"]//thead//tr/th/text()')\n",
    "            columns = [c.strip() for c in columns]\n",
    "\n",
    "            # Scrape the list of rows\n",
    "            rows = tree.xpath(f'//table[@id=\"{table_id}\"]//tbody//tr')\n",
    "            data = []\n",
    "\n",
    "            # Extract data from each row\n",
    "            for row in rows:\n",
    "                row_data = []\n",
    "                for r in row.xpath('.//td | .//th'):\n",
    "                    row_data.append(r.text_content().strip())\n",
    "                # Ensure each row has the same number of columns as the header\n",
    "                while len(row_data) < len(columns):\n",
    "                    row_data.append(None)\n",
    "                while len(row_data) > len(columns):\n",
    "                    row_data.pop()\n",
    "                data.append(row_data)  # Append the row data to the data list\n",
    "\n",
    "            # Create a DataFrame\n",
    "            df = pd.DataFrame(data, columns=columns)\n",
    "            \n",
    "            # Save the DataFrame to a CSV file without using any column as an index\n",
    "            df.to_csv(f\"{url_list[url]}_pfr_combine.csv\", index=False)\n",
    "        else:\n",
    "            print(f\"Failed to fetch the webpage. Status code: {response.status_code}\")\n",
    "\n",
    "# URL list\n",
    "combine_list = {'https://www.pro-football-reference.com/draft/2000-combine.htm': 2000,\n",
    "                'https://www.pro-football-reference.com/draft/2001-combine.htm': 2001,\n",
    "                'https://www.pro-football-reference.com/draft/2002-combine.htm': 2002,\n",
    "                'https://www.pro-football-reference.com/draft/2003-combine.htm': 2003,\n",
    "                'https://www.pro-football-reference.com/draft/2004-combine.htm': 2004,\n",
    "                'https://www.pro-football-reference.com/draft/2005-combine.htm': 2005,\n",
    "                'https://www.pro-football-reference.com/draft/2006-combine.htm': 2006,\n",
    "                'https://www.pro-football-reference.com/draft/2007-combine.htm': 2007,\n",
    "                'https://www.pro-football-reference.com/draft/2008-combine.htm': 2008,\n",
    "                'https://www.pro-football-reference.com/draft/2009-combine.htm': 2009,\n",
    "                'https://www.pro-football-reference.com/draft/2010-combine.htm': 2010,\n",
    "                'https://www.pro-football-reference.com/draft/2011-combine.htm': 2011,\n",
    "                'https://www.pro-football-reference.com/draft/2012-combine.htm': 2012,\n",
    "                'https://www.pro-football-reference.com/draft/2013-combine.htm': 2013,\n",
    "                'https://www.pro-football-reference.com/draft/2014-combine.htm': 2014,\n",
    "                'https://www.pro-football-reference.com/draft/2015-combine.htm': 2015,\n",
    "                'https://www.pro-football-reference.com/draft/2016-combine.htm': 2016,\n",
    "                'https://www.pro-football-reference.com/draft/2017-combine.htm': 2017,\n",
    "                'https://www.pro-football-reference.com/draft/2018-combine.htm': 2018,\n",
    "                'https://www.pro-football-reference.com/draft/2019-combine.htm': 2019,\n",
    "                'https://www.pro-football-reference.com/draft/2020-combine.htm': 2020,\n",
    "                'https://www.pro-football-reference.com/draft/2021-combine.htm': 2021,\n",
    "                'https://www.pro-football-reference.com/draft/2022-combine.htm': 2022,\n",
    "                'https://www.pro-football-reference.com/draft/2023-combine.htm': 2023\n",
    "}\n",
    "\n",
    "fetch_data(combine_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Player   Age   Tm Pos     G    GS    Cmp    Att  Cmp%     Yds  ...  \\\n",
      "0  Drew Brees  33.0  NOR  QB  16.0  16.0  422.0  670.0  63.0  5177.0  ...   \n",
      "\n",
      "   NY/A  ANY/A  4QC  GWD  Wins  ProBowl  AllPro  MVP  Passing_Points  Year  \n",
      "0  7.17   7.17  1.0  2.0     7        1       0    0          341.08  2012  \n",
      "\n",
      "[1 rows x 36 columns]\n",
      "Index(['Player', 'Age', 'Tm', 'Pos', 'G', 'GS', 'Cmp', 'Att', 'Cmp%', 'Yds',\n",
      "       'TD', 'TD%', 'Int', 'Int%', '1D', 'Succ%', 'Lng', 'Y/A', 'AY/A', 'Y/C',\n",
      "       'Y/G', 'Rate', 'QBR', 'Sk', 'Sack_Yds', 'Sk%', 'NY/A', 'ANY/A', '4QC',\n",
      "       'GWD', 'Wins', 'ProBowl', 'AllPro', 'MVP', 'Passing_Points', 'Year'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Quarterback cleaning\n",
    "passes = {}\n",
    "for year in range(2012, 2024):\n",
    "    passes[year] = pd.read_csv(f'{year}_pfr_passing.csv')\n",
    "\n",
    "# Cleaning\n",
    "for year in range(2012, 2024):\n",
    "    # Change 'Team' to 'Tm'\n",
    "    passes[year] = passes[year].rename(columns={'Team': 'Tm'})\n",
    "    # Change Yds.1 to Rush_Yds\n",
    "    passes[year] = passes[year].rename(columns={'Yds.1': 'Sack_Yds'})\n",
    "    # Split QBrec into Wins and Losses and ties\n",
    "    passes[year][['Wins', 'Losses', 'Ties']] = passes[year]['QBrec'].str.split('-', expand=True)\n",
    "    passes[year] = passes[year].drop(columns=['QBrec', 'Losses', 'Ties'])\n",
    "    # Fill NaN values in Awards column with an empty string\n",
    "    passes[year]['Awards'] = passes[year]['Awards'].fillna('')\n",
    "    # New Column ProBowl which is 1 if 'PB' is in Awards column\n",
    "    passes[year]['ProBowl'] = passes[year]['Awards'].str.contains('PB').astype(int)\n",
    "    # New Column AllPro which is 1 if 'AP' is in Awards column\n",
    "    passes[year]['AllPro'] = passes[year]['Awards'].str.contains('AP').astype(int)\n",
    "    # New column MVP which is 1 if 'MVP' is in Awards column\n",
    "    passes[year]['MVP'] = passes[year]['Awards'].str.contains('MVP').astype(int)\n",
    "    # Drop Awards\n",
    "    passes[year] = passes[year].drop(columns=['Awards'])\n",
    "    # New column Passing_Points which is Yds*0.04 + TD*4 - Int*2\n",
    "    passes[year]['Passing_Points'] = passes[year]['Yds'].astype(float)*0.04 + passes[year]['TD'].astype(float)*4 - passes[year]['Int'].astype(float)*2\n",
    "    # New column Year\n",
    "    passes[year]['Year'] = year\n",
    "\n",
    "# Output\n",
    "print(passes[2012].head(1))\n",
    "print(passes[2012].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Player   Tm  Age Pos   G  GS  Tgt  Rec Ctch%   Yds  ...  Succ%  \\\n",
      "0  Calvin Johnson  DET   27  WR  16  16  204  122  59.8  1964  ...   55.4   \n",
      "\n",
      "   Lng  Y/Tgt  R/G    Y/G  Fmb  AllPro  ProBowl  Receiving_Points  Year  \n",
      "0   53    9.6  7.6  122.8    3       1        1             287.4  2012  \n",
      "\n",
      "[1 rows x 23 columns]\n",
      "Index(['Player', 'Tm', 'Age', 'Pos', 'G', 'GS', 'Tgt', 'Rec', 'Ctch%', 'Yds',\n",
      "       'Y/R', 'TD', '1D', 'Succ%', 'Lng', 'Y/Tgt', 'R/G', 'Y/G', 'Fmb',\n",
      "       'AllPro', 'ProBowl', 'Receiving_Points', 'Year'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Receiving cleaning\n",
    "recs = {}\n",
    "for year in range(2012, 2024):\n",
    "    recs[year] = pd.read_csv(f'{year}_pfr_receiving.csv')\n",
    "\n",
    "# Cleaning\n",
    "for year in range(2012, 2024):\n",
    "    # Drop 'Rk' column\n",
    "    recs[year].drop(columns=['Rk'], inplace=True)\n",
    "    recs[year] = recs[year].drop(columns=['Player-additional'])\n",
    "    # New column AllPro which is 1 if + is in Player column\n",
    "    recs[year]['AllPro'] = recs[year]['Player'].str.contains('\\+').astype(int)\n",
    "    # New column ProBowl which is 1 if * is in Player column\n",
    "    recs[year]['ProBowl'] = recs[year]['Player'].str.contains('\\*').astype(int)\n",
    "    # Remove + and * from Player column\n",
    "    recs[year]['Player'] = recs[year]['Player'].str.replace('+', '')\n",
    "    recs[year]['Player'] = recs[year]['Player'].str.replace('*', '')\n",
    "    # Remove % from Ctch% column\n",
    "    recs[year]['Ctch%'] = recs[year]['Ctch%'].str.replace('%', '')\n",
    "    # New column Receiving_Points which is Rec*0.5 + Yds*0.1 + TD*6\n",
    "    recs[year]['Receiving_Points'] = recs[year]['Rec'].astype(int)*0.5 + recs[year]['Yds'].astype(int)*0.1 + recs[year]['TD'].astype(int)*6\n",
    "    # New column Year\n",
    "    recs[year]['Year'] = year\n",
    "\n",
    "# Output\n",
    "print(recs[2012].head(1))\n",
    "print(recs[2012].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Player   Tm  Age Pos   G  GS  Att   Yds  TD  1D  Lng  Y/A   Y/G  Fmb  \\\n",
      "0  Arian Foster  HOU   26  RB  16  16  351  1424  15  78   46  4.1  89.0    3   \n",
      "\n",
      "   AllPro  ProBowl  Rushing_Points  Year  \n",
      "0       0        1           226.4  2012  \n",
      "Index(['Player', 'Tm', 'Age', 'Pos', 'G', 'GS', 'Att', 'Yds', 'TD', '1D',\n",
      "       'Lng', 'Y/A', 'Y/G', 'Fmb', 'AllPro', 'ProBowl', 'Rushing_Points',\n",
      "       'Year'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Rushing cleaning\n",
    "rushes = {}\n",
    "for year in range(2012, 2024):\n",
    "    rushes[year] = pd.read_csv(f'{year}_pfr_rushing.csv')\n",
    "\n",
    "# Cleaning\n",
    "for year in range(2012, 2024):\n",
    "    # Drop 'Rk' column\n",
    "    rushes[year].drop(columns=['Rk'], inplace=True)\n",
    "    # Rename -9999 to Player-additional column\n",
    "    rushes[year] = rushes[year].rename(columns={'-9999': 'Player-additional'})\n",
    "    rushes[year] = rushes[year].drop(columns=['Player-additional'])\n",
    "    # New column AllPro which is 1 if + is in Player column\n",
    "    rushes[year]['AllPro'] = rushes[year]['Player'].str.contains('\\+').astype(int)\n",
    "    # New column ProBowl which is 1 if * is in Player column\n",
    "    rushes[year]['ProBowl'] = rushes[year]['Player'].str.contains('\\*').astype(int)\n",
    "    # Remove + and * from Player column\n",
    "    rushes[year]['Player'] = rushes[year]['Player'].str.replace('+', '')\n",
    "    rushes[year]['Player'] = rushes[year]['Player'].str.replace('*', '')\n",
    "    # New column Rushing_Points which is Yds*0.1 + TD*6 - Fmb*2\n",
    "    rushes[year]['Rushing_Points'] = rushes[year]['Yds'].astype(int)*0.1 + rushes[year]['TD'].astype(int)*6 - rushes[year]['Fmb'].astype(int)*2\n",
    "    # New column Year\n",
    "    rushes[year]['Year'] = year\n",
    "\n",
    "# Output   \n",
    "print(rushes[2012].head(1))\n",
    "print(rushes[2012].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary for Team Names\n",
    "team_names = {\n",
    "    'Arizona Cardinals': 'ARI',\n",
    "    'Atlanta Falcons': 'ATL',\n",
    "    'Baltimore Ravens': 'BAL',\n",
    "    'Buffalo Bills': 'BUF',\n",
    "    'Carolina Panthers': 'CAR',\n",
    "    'Chicago Bears': 'CHI',\n",
    "    'Cincinnati Bengals': 'CIN',\n",
    "    'Cleveland Browns': 'CLE',\n",
    "    'Dallas Cowboys': 'DAL',\n",
    "    'Denver Broncos': 'DEN',\n",
    "    'Detroit Lions': 'DET',\n",
    "    'Green Bay Packers': 'GNB',\n",
    "    'Houston Texans': 'HOU',\n",
    "    'Indianapolis Colts': 'IND',\n",
    "    'Jacksonville Jaguars': 'JAX',\n",
    "    'Kansas City Chiefs': 'KAN',\n",
    "    'Las Vegas Raiders': 'LVR',\n",
    "    'Los Angeles Chargers': 'LAC',\n",
    "    'Los Angeles Rams': 'LAR',\n",
    "    'Miami Dolphins': 'MIA',\n",
    "    'Minnesota Vikings': 'MIN',\n",
    "    'New England Patriots': 'NWE',\n",
    "    'New Orleans Saints': 'NOR',\n",
    "    'New York Giants': 'NYG',\n",
    "    'New York Jets': 'NYJ',\n",
    "    'Oakland Raiders': 'OAK',\n",
    "    'Philadelphia Eagles': 'PHI',\n",
    "    'Pittsburgh Steelers': 'PIT',\n",
    "    'St. Louis Rams': 'STL',\n",
    "    'San Francisco 49ers': 'SFO',\n",
    "    'San Diego Chargers': 'SDG',\n",
    "    'Seattle Seahawks': 'SEA',\n",
    "    'Tampa Bay Buccaneers': 'TAM',\n",
    "    'Tennessee Titans': 'TEN',\n",
    "    'Washington Football Team': 'WAS',\n",
    "    'Washington Redskins': 'WAS'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Team_Name   G   PF   Yds   Ply  Y/P  TO  FL  1stD  Cmp  ...  \\\n",
      "0  New England Patriots  16  557  6846  1191  5.7  16   7   444  402  ...   \n",
      "\n",
      "   YdsPer_Rush  1stD_Rush  Pen  Yds_Pen  1stPy   Sc%  TO%     EXP   Tm  Year  \n",
      "0          4.2        151   97      840     37  48.1  8.1  118.97  NWE  2012  \n",
      "\n",
      "[1 rows x 29 columns]\n",
      "Index(['Team_Name', 'G', 'PF', 'Yds', 'Ply', 'Y/P', 'TO', 'FL', '1stD', 'Cmp',\n",
      "       'Att_Pass', 'Yds_Pass', 'TD_Pass', 'Int', 'NY/A', '1stD_Pass',\n",
      "       'Att_Rush', 'Yds_Rush', 'TD_Rush', 'YdsPer_Rush', '1stD_Rush', 'Pen',\n",
      "       'Yds_Pen', '1stPy', 'Sc%', 'TO%', 'EXP', 'Tm', 'Year'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Team Offense cleaning\n",
    "teams = {}\n",
    "\n",
    "for year in range(2012, 2024):\n",
    "    teams[year] = pd.read_csv(f'{year}_pfr_team_stats.csv')\n",
    "\n",
    "# Cleaning\n",
    "for year in range(2012, 2024):\n",
    "    # Rename 1stD.1 to 1stD_Pass\n",
    "    teams[year] = teams[year].rename(columns={'Yds.1': 'Yds_Pass'})\n",
    "    teams[year] = teams[year].rename(columns={'1stD.1': '1stD_Pass'})\n",
    "    teams[year] = teams[year].rename(columns={'TD': 'TD_Pass'})\n",
    "    teams[year] = teams[year].rename(columns={'Att': 'Att_Pass'})\n",
    "    # Rename 1stD.2 to 1stD_Rush\n",
    "    teams[year] = teams[year].rename(columns={'Att.1': 'Att_Rush'})\n",
    "    teams[year] = teams[year].rename(columns={'Yds.2': 'Yds_Rush'})\n",
    "    teams[year] = teams[year].rename(columns={'TD.1': 'TD_Rush'})\n",
    "    teams[year] = teams[year].rename(columns={'1stD.2': '1stD_Rush'})\n",
    "    teams[year] = teams[year].rename(columns={'Y/A': 'YdsPer_Rush'})\n",
    "    # Rename Yds.3 to Yds_Pen\n",
    "    teams[year] = teams[year].rename(columns={'Yds.3': 'Yds_Pen'})\n",
    "    # Rename Tm to Team_Name\n",
    "    teams[year] = teams[year].rename(columns={'Tm': 'Team_Name'})\n",
    "    # New column that uses team_names dictionary to convert Team_Name to Tm\n",
    "    teams[year]['Tm'] = teams[year]['Team_Name'].map(team_names)\n",
    "    # New column Year\n",
    "    teams[year]['Year'] = year\n",
    "\n",
    "# Output\n",
    "print(teams[2012].head(1))\n",
    "print(teams[2012].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Player  Pos          School     Wt  40yd  Vertical  Bench  \\\n",
      "0     John Abraham  OLB  South Carolina  252.0  4.55       NaN    NaN   \n",
      "1  Shaun Alexander   RB         Alabama  218.0  4.58       NaN    NaN   \n",
      "2   Darnell Alford   OT     Boston Col.  334.0  5.56      25.0   23.0   \n",
      "\n",
      "   Broad Jump  3Cone  Shuttle  Height           Team_Name  Round  Pick   Year  \\\n",
      "0         NaN    NaN      NaN      76       New York Jets   1st     13   2000   \n",
      "1         NaN    NaN      NaN      72    Seattle Seahawks   1st     19   2000   \n",
      "2        94.0   8.48     4.98      76  Kansas City Chiefs   6th    188   2000   \n",
      "\n",
      "    Tm  \n",
      "0  NYJ  \n",
      "1  SEA  \n",
      "2  KAN  \n",
      "Index(['Player', 'Pos', 'School', 'Wt', '40yd', 'Vertical', 'Bench',\n",
      "       'Broad Jump', '3Cone', 'Shuttle', 'Height', 'Team_Name', 'Round',\n",
      "       'Pick', 'Year', 'Tm'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Combine cleaning\n",
    "combines = {}\n",
    "for year in range(2000, 2024):\n",
    "    combines[year] = pd.read_csv(f'{year}_pfr_combine.csv')\n",
    "\n",
    "# Cleaning\n",
    "for year in range(2000, 2024):\n",
    "    # Remove College column\n",
    "    combines[year] = combines[year].drop(columns=['College'])\n",
    "    # Split Ht into Feet and Inches at the dash\n",
    "    combines[year][['Feet', 'Inches']] = combines[year]['Ht'].str.split('-', expand=True)\n",
    "    # Replace None and nan with 0 in the Inches column\n",
    "    combines[year]['Inches'] = combines[year]['Inches'].replace([None, np.nan], '0')\n",
    "    combines[year]['Feet'] = combines[year]['Feet'].replace(['Ht', np.nan], '5')\n",
    "    # Convert both columns to integers\n",
    "    combines[year]['Feet'] = combines[year]['Feet'].astype(int)\n",
    "    combines[year]['Inches'] = combines[year]['Inches'].astype(int)\n",
    "    # New column Height which is the sum of Feet and Inches\n",
    "    combines[year]['Height'] = combines[year]['Feet'].astype(int) * 12 + combines[year]['Inches'].astype(int)\n",
    "    # Drop Ht, Feet, Inches\n",
    "    combines[year] = combines[year].drop(columns=['Ht', 'Feet', 'Inches'])\n",
    "    # Split Drafted (tm/rnd/yr) into Tm, Round, Pick, and Year\n",
    "    combines[year][['Tm', 'Round', 'Pick', 'Year']] = combines[year]['Drafted (tm/rnd/yr)'].str.split('/', expand=True)\n",
    "    combines[year] = combines[year].drop(columns=['Drafted (tm/rnd/yr)'])\n",
    "    # Split pick into Pick and letters at the first letter\n",
    "    combines[year][['Pick', 'Let', 'letter', 'extra', 'bub']] = combines[year]['Pick'].str.split('([A-Za-z]+)', expand=True)\n",
    "    combines[year] = combines[year].drop(columns=['Let', 'letter', 'extra', 'bub'])\n",
    "    # Rename Tm to Team_Name\n",
    "    combines[year] = combines[year].rename(columns={'Tm': 'Team_Name'})\n",
    "    # Strip whitespace from Team_Name\n",
    "    combines[year]['Team_Name'] = combines[year]['Team_Name'].str.strip()\n",
    "    # New column that uses team_names dictionary to convert Team_Name to Tm for non-empty values\n",
    "    combines[year]['Tm'] = combines[year]['Team_Name'].map(team_names)\n",
    "    # Convert  Wt  40yd Vertical Bench Broad Jump 3Cone Shuttle  Height to numeric\n",
    "    combines[year]['Wt'] = pd.to_numeric(combines[year]['Wt'], errors='coerce')\n",
    "    combines[year]['40yd'] = pd.to_numeric(combines[year]['40yd'], errors='coerce')\n",
    "    combines[year]['Vertical'] = pd.to_numeric(combines[year]['Vertical'], errors='coerce')\n",
    "    combines[year]['Bench'] = pd.to_numeric(combines[year]['Bench'], errors='coerce')\n",
    "    combines[year]['Broad Jump'] = pd.to_numeric(combines[year]['Broad Jump'], errors='coerce')\n",
    "    combines[year]['3Cone'] = pd.to_numeric(combines[year]['3Cone'], errors='coerce')\n",
    "    combines[year]['Shuttle'] = pd.to_numeric(combines[year]['Shuttle'], errors='coerce')\n",
    "    combines[year]['Height'] = pd.to_numeric(combines[year]['Height'], errors='coerce')\n",
    "\n",
    "# Output\n",
    "print(combines[2000].head(3))\n",
    "print(combines[2000].columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine passing data\n",
    "qb_data = pd.concat(passes.values(), ignore_index=True)\n",
    "# Combine receiving data\n",
    "rec_data = pd.concat(recs.values(), ignore_index=True)\n",
    "# Combine rushing data\n",
    "rush_data = pd.concat(rushes.values(), ignore_index=True)\n",
    "# Combine team offense data\n",
    "team_data = pd.concat(teams.values(), ignore_index=True)\n",
    "# Combine combine data\n",
    "combine_data = pd.concat(combines.values(), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save qb_data\n",
    "qb_data.to_csv('gross_pfr_passing.csv', index=False)\n",
    "# Save rec_data\n",
    "rec_data.to_csv('gross_pfr_receiving.csv', index=False)\n",
    "# Save rush_data\n",
    "rush_data.to_csv('gross_pfr_rushing.csv', index=False)\n",
    "# Save team_data\n",
    "team_data.to_csv('gross_pfr_team_offense.csv', index=False)\n",
    "# Save combine_data\n",
    "combine_data.to_csv('gross_pfr_combine.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
